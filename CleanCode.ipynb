{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PliJrMdSvnMl",
    "outputId": "23286359-f3f1-423c-d307-f95b6e19fbcb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "# from tensorflow.python.keras._impl import keras\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, AveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.layers import Input\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "import keras.layers \n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "LLla0V4tvnMx",
    "outputId": "f838039f-881f-43ea-d479-7314e29a0f7e"
   },
   "outputs": [],
   "source": [
    "#Import data\n",
    "X = pd.read_pickle('train_max_x')\n",
    "y = pd.read_csv('train_max_y.csv')\n",
    "y = y['Label']\n",
    "\n",
    "X = X.astype('float32')/255\n",
    "X = np.repeat(X.reshape(X.shape[0], 128, 128, 1), 1, axis=1)\n",
    "#X = tf.image.grayscale_to_rgb(X)\n",
    "y = to_categorical(y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Cy0fT-67R-KG",
    "outputId": "16b965ea-488f-4a73-822e-77c1837aa7e7"
   },
   "outputs": [],
   "source": [
    "#Original model\n",
    "model = keras.Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5,5), activation='relu', input_shape=(128,128,1)))\n",
    "model.add(keras.layers.Dropout(0.01, noise_shape=None, seed=None))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu')) \n",
    "model.add(keras.layers.Dropout(0.01, noise_shape=None, seed=None))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu')) \n",
    "model.add(keras.layers.Dropout(0.01, noise_shape=None, seed=None))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu')) \n",
    "model.add(keras.layers.Dropout(0.01, noise_shape=None, seed=None))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual model\n",
    "model2 = keras.Sequential()\n",
    "model2.add(Conv2D(32, kernel_size=(5,5), activation='relu', input_shape=(128,128,1)))\n",
    "model2.add(keras.layers.Dropout(0.01, noise_shape=None, seed=None))\n",
    "model2.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "model2.add(Conv2D(64, kernel_size=(3,3), activation='relu')) \n",
    "model2.add(keras.layers.Dropout(0.01, noise_shape=None, seed=None))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Conv2D(128, kernel_size=(3,3), activation='relu')) \n",
    "model2.add(keras.layers.Dropout(0.01, noise_shape=None, seed=None))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Conv2D(230, kernel_size=(3,3), activation='relu')) \n",
    "model2.add(keras.layers.Dropout(0.01, noise_shape=None, seed=None))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = keras.Sequential()\n",
    "model3.add(Conv2D(32, kernel_size=(5,5), activation='relu', input_shape=(128,128,1)))\n",
    "model3.add(keras.layers.Dropout(0.01, noise_shape=None, seed=None))\n",
    "model3.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "\n",
    "model3.add(Conv2D(64, kernel_size=(4,4), activation='relu'))\n",
    "model3.add(keras.layers.Dropout(0.01, noise_shape=None, seed=None))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model3.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model3.add(keras.layers.Dropout(0.01, noise_shape=None, seed=None))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model3.add(Conv2D(230, kernel_size=(3,3), activation='relu')) \n",
    "model3.add(keras.layers.Dropout(0.01, noise_shape=None, seed=None))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(10, activation='softmax'))\n",
    "model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 511
    },
    "colab_type": "code",
    "id": "NOSQ5yUevnND",
    "outputId": "4e670016-9068-444b-c125-bdaa662773a5"
   },
   "outputs": [],
   "source": [
    "#final home-made CNN model\n",
    "modelfinal = keras.Sequential()\n",
    "modelfinal.add(Conv2D(32, kernel_size=(5,5), activation='relu', input_shape=(128,128,1)))\n",
    "modelfinal.add(keras.layers.Dropout(0.01, noise_shape=None, seed=None))\n",
    "modelfinal.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "\n",
    "modelfinal.add(Conv2D(64, kernel_size=(4,4), activation='relu'))\n",
    "modelfinal.add(keras.layers.Dropout(0.01, noise_shape=None, seed=None))\n",
    "modelfinal.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "modelfinal.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "modelfinal.add(keras.layers.Dropout(0.01, noise_shape=None, seed=None))\n",
    "modelfinal.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "modelfinal.add(Conv2D(230, kernel_size=(3,3), activation='relu')) \n",
    "modelfinal.add(keras.layers.Dropout(0.01, noise_shape=None, seed=None))\n",
    "modelfinal.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "modelfinal.add(Flatten())\n",
    "\n",
    "modelfinal.add(Dense(10, activation='softmax'))\n",
    "modelfinal.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "167/167 [==============================] - 62s 372ms/step - loss: 1.8972 - accuracy: 0.2578 - val_loss: 1.8334 - val_accuracy: 0.2756\n",
      "Epoch 2/30\n",
      "167/167 [==============================] - 57s 342ms/step - loss: 1.8011 - accuracy: 0.3111 - val_loss: 1.6362 - val_accuracy: 0.3504\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 57s 342ms/step - loss: 1.6789 - accuracy: 0.3766 - val_loss: 1.6061 - val_accuracy: 0.4285\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 57s 341ms/step - loss: 1.5460 - accuracy: 0.4441 - val_loss: 1.5999 - val_accuracy: 0.4699\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 57s 343ms/step - loss: 1.4182 - accuracy: 0.4805 - val_loss: 1.3834 - val_accuracy: 0.5180\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 57s 341ms/step - loss: 1.3254 - accuracy: 0.5182 - val_loss: 1.4038 - val_accuracy: 0.5488\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 57s 342ms/step - loss: 1.2073 - accuracy: 0.5649 - val_loss: 1.3198 - val_accuracy: 0.5816\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 57s 342ms/step - loss: 1.1327 - accuracy: 0.6010 - val_loss: 1.1789 - val_accuracy: 0.5880\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 57s 344ms/step - loss: 1.0847 - accuracy: 0.6189 - val_loss: 1.1023 - val_accuracy: 0.6297\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 57s 342ms/step - loss: 1.0254 - accuracy: 0.6385 - val_loss: 1.0897 - val_accuracy: 0.6469\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 59s 352ms/step - loss: 1.0015 - accuracy: 0.6540 - val_loss: 0.9689 - val_accuracy: 0.6605\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 57s 341ms/step - loss: 0.9673 - accuracy: 0.6663 - val_loss: 1.1577 - val_accuracy: 0.6721\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.9775 - accuracy: 0.6673 - val_loss: 1.1015 - val_accuracy: 0.6237\n",
      "Epoch 14/30\n",
      " 11/167 [>.............................] - ETA: 51s - loss: 1.0073 - accuracy: 0.6548"
     ]
    }
   ],
   "source": [
    "history2 = model1.fit_generator(training_data, \n",
    "                              epochs=30, verbose=1,\n",
    "                              validation_data=validation_data\n",
    "                              )\n",
    "with open('./InceptionV3_fitgen_history2.pickle', 'wb') as f:\n",
    "     pickle.dump(history2.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 511
    },
    "colab_type": "code",
    "id": "NOSQ5yUevnND",
    "outputId": "4e670016-9068-444b-c125-bdaa662773a5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "167/167 [==============================] - 64s 383ms/step - loss: 1.8966 - categorical_accuracy: 0.2617 - val_loss: 1.9569 - val_categorical_accuracy: 0.2725\n",
      "Epoch 2/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 1.8640 - categorical_accuracy: 0.2742 - val_loss: 1.6934 - val_categorical_accuracy: 0.3256\n",
      "Epoch 3/400\n",
      "167/167 [==============================] - 58s 350ms/step - loss: 1.7587 - categorical_accuracy: 0.3402 - val_loss: 1.7047 - val_categorical_accuracy: 0.3527\n",
      "Epoch 4/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 1.6522 - categorical_accuracy: 0.3967 - val_loss: 1.6077 - val_categorical_accuracy: 0.4296\n",
      "Epoch 5/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 1.5693 - categorical_accuracy: 0.4416 - val_loss: 1.5661 - val_categorical_accuracy: 0.4503\n",
      "Epoch 6/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 1.4699 - categorical_accuracy: 0.4675 - val_loss: 1.3865 - val_categorical_accuracy: 0.4739\n",
      "Epoch 7/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 1.3919 - categorical_accuracy: 0.4895 - val_loss: 1.2963 - val_categorical_accuracy: 0.5045\n",
      "Epoch 8/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 1.3159 - categorical_accuracy: 0.5225 - val_loss: 1.3081 - val_categorical_accuracy: 0.5508\n",
      "Epoch 9/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 1.2038 - categorical_accuracy: 0.5634 - val_loss: 1.2464 - val_categorical_accuracy: 0.5803\n",
      "Epoch 10/400\n",
      "167/167 [==============================] - 58s 350ms/step - loss: 1.1631 - categorical_accuracy: 0.5825 - val_loss: 0.9010 - val_categorical_accuracy: 0.5975\n",
      "Epoch 11/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 1.1027 - categorical_accuracy: 0.6121 - val_loss: 0.9514 - val_categorical_accuracy: 0.6349\n",
      "Epoch 12/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 1.0426 - categorical_accuracy: 0.6338 - val_loss: 1.0448 - val_categorical_accuracy: 0.6411\n",
      "Epoch 13/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 1.0211 - categorical_accuracy: 0.6459 - val_loss: 1.1345 - val_categorical_accuracy: 0.6484\n",
      "Epoch 14/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.9848 - categorical_accuracy: 0.6588 - val_loss: 0.9925 - val_categorical_accuracy: 0.6735\n",
      "Epoch 15/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.9572 - categorical_accuracy: 0.6713 - val_loss: 0.8888 - val_categorical_accuracy: 0.6731\n",
      "Epoch 16/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.9593 - categorical_accuracy: 0.6728 - val_loss: 0.7464 - val_categorical_accuracy: 0.6840\n",
      "Epoch 17/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.9140 - categorical_accuracy: 0.6864 - val_loss: 0.8631 - val_categorical_accuracy: 0.6892\n",
      "Epoch 18/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.9088 - categorical_accuracy: 0.6930 - val_loss: 0.9714 - val_categorical_accuracy: 0.6912\n",
      "Epoch 19/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.8845 - categorical_accuracy: 0.6965 - val_loss: 1.0748 - val_categorical_accuracy: 0.7040\n",
      "Epoch 20/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.8759 - categorical_accuracy: 0.7018 - val_loss: 0.8637 - val_categorical_accuracy: 0.7139\n",
      "Epoch 21/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.8674 - categorical_accuracy: 0.7070 - val_loss: 0.8428 - val_categorical_accuracy: 0.7067\n",
      "Epoch 22/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.8518 - categorical_accuracy: 0.7093 - val_loss: 0.6315 - val_categorical_accuracy: 0.7152\n",
      "Epoch 23/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.8370 - categorical_accuracy: 0.7181 - val_loss: 0.8843 - val_categorical_accuracy: 0.7161\n",
      "Epoch 24/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.8272 - categorical_accuracy: 0.7195 - val_loss: 0.7133 - val_categorical_accuracy: 0.7173\n",
      "Epoch 25/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.8369 - categorical_accuracy: 0.7202 - val_loss: 0.8970 - val_categorical_accuracy: 0.7307\n",
      "Epoch 26/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.8319 - categorical_accuracy: 0.7219 - val_loss: 1.0474 - val_categorical_accuracy: 0.7261\n",
      "Epoch 27/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.8082 - categorical_accuracy: 0.7296 - val_loss: 0.6698 - val_categorical_accuracy: 0.7245\n",
      "Epoch 28/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.8012 - categorical_accuracy: 0.7317 - val_loss: 0.7446 - val_categorical_accuracy: 0.7372\n",
      "Epoch 29/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.8110 - categorical_accuracy: 0.7291 - val_loss: 0.6821 - val_categorical_accuracy: 0.7348\n",
      "Epoch 30/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.8008 - categorical_accuracy: 0.7326 - val_loss: 0.7954 - val_categorical_accuracy: 0.7348\n",
      "Epoch 31/400\n",
      "167/167 [==============================] - 58s 350ms/step - loss: 0.8304 - categorical_accuracy: 0.7213 - val_loss: 0.7448 - val_categorical_accuracy: 0.7288\n",
      "Epoch 32/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.7985 - categorical_accuracy: 0.7334 - val_loss: 0.7264 - val_categorical_accuracy: 0.7347\n",
      "Epoch 33/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.7888 - categorical_accuracy: 0.7376 - val_loss: 0.7816 - val_categorical_accuracy: 0.7449\n",
      "Epoch 34/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.7652 - categorical_accuracy: 0.7446 - val_loss: 0.7291 - val_categorical_accuracy: 0.7469\n",
      "Epoch 35/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.7627 - categorical_accuracy: 0.7460 - val_loss: 0.7484 - val_categorical_accuracy: 0.7452\n",
      "Epoch 36/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.7589 - categorical_accuracy: 0.7506 - val_loss: 0.8648 - val_categorical_accuracy: 0.7355\n",
      "Epoch 37/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.7511 - categorical_accuracy: 0.7498 - val_loss: 0.9042 - val_categorical_accuracy: 0.7489\n",
      "Epoch 38/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.7472 - categorical_accuracy: 0.7511 - val_loss: 0.7676 - val_categorical_accuracy: 0.7540\n",
      "Epoch 39/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.7417 - categorical_accuracy: 0.7532 - val_loss: 0.8097 - val_categorical_accuracy: 0.7464\n",
      "Epoch 40/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.7468 - categorical_accuracy: 0.7527 - val_loss: 0.7603 - val_categorical_accuracy: 0.7483\n",
      "Epoch 41/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.7526 - categorical_accuracy: 0.7522 - val_loss: 0.7473 - val_categorical_accuracy: 0.7505\n",
      "Epoch 42/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.7330 - categorical_accuracy: 0.7591 - val_loss: 0.7547 - val_categorical_accuracy: 0.7524\n",
      "Epoch 43/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.7399 - categorical_accuracy: 0.7564 - val_loss: 0.6349 - val_categorical_accuracy: 0.7592\n",
      "Epoch 44/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.7307 - categorical_accuracy: 0.7584 - val_loss: 0.7655 - val_categorical_accuracy: 0.7581\n",
      "Epoch 45/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.7358 - categorical_accuracy: 0.7554 - val_loss: 0.6660 - val_categorical_accuracy: 0.7539\n",
      "Epoch 46/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.7235 - categorical_accuracy: 0.7631 - val_loss: 0.9441 - val_categorical_accuracy: 0.7644\n",
      "Epoch 47/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.7161 - categorical_accuracy: 0.7638 - val_loss: 0.7667 - val_categorical_accuracy: 0.7563\n",
      "Epoch 48/400\n",
      "167/167 [==============================] - 58s 350ms/step - loss: 0.7247 - categorical_accuracy: 0.7603 - val_loss: 0.6496 - val_categorical_accuracy: 0.7680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.7136 - categorical_accuracy: 0.7634 - val_loss: 0.7666 - val_categorical_accuracy: 0.7605\n",
      "Epoch 50/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.7227 - categorical_accuracy: 0.7628 - val_loss: 0.8433 - val_categorical_accuracy: 0.7608\n",
      "Epoch 51/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.7100 - categorical_accuracy: 0.7653 - val_loss: 0.7833 - val_categorical_accuracy: 0.7540\n",
      "Epoch 52/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.7268 - categorical_accuracy: 0.7630 - val_loss: 0.5237 - val_categorical_accuracy: 0.7393\n",
      "Epoch 53/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.7198 - categorical_accuracy: 0.7626 - val_loss: 0.8549 - val_categorical_accuracy: 0.7621\n",
      "Epoch 54/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.7182 - categorical_accuracy: 0.7655 - val_loss: 0.8659 - val_categorical_accuracy: 0.7637\n",
      "Epoch 55/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.7012 - categorical_accuracy: 0.7681 - val_loss: 0.6655 - val_categorical_accuracy: 0.7625\n",
      "Epoch 56/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.7325 - categorical_accuracy: 0.7592 - val_loss: 0.7203 - val_categorical_accuracy: 0.7733\n",
      "Epoch 57/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.6965 - categorical_accuracy: 0.7716 - val_loss: 0.8282 - val_categorical_accuracy: 0.7633\n",
      "Epoch 58/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.7060 - categorical_accuracy: 0.7677 - val_loss: 0.7151 - val_categorical_accuracy: 0.7672\n",
      "Epoch 59/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.6865 - categorical_accuracy: 0.7730 - val_loss: 0.5498 - val_categorical_accuracy: 0.7675\n",
      "Epoch 60/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.6894 - categorical_accuracy: 0.7740 - val_loss: 0.7134 - val_categorical_accuracy: 0.7733\n",
      "Epoch 61/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.7000 - categorical_accuracy: 0.7729 - val_loss: 0.7937 - val_categorical_accuracy: 0.7735\n",
      "Epoch 62/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.6757 - categorical_accuracy: 0.7775 - val_loss: 0.6171 - val_categorical_accuracy: 0.7612\n",
      "Epoch 63/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.6951 - categorical_accuracy: 0.7717 - val_loss: 0.5797 - val_categorical_accuracy: 0.7721\n",
      "Epoch 64/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.6905 - categorical_accuracy: 0.7725 - val_loss: 0.7080 - val_categorical_accuracy: 0.7723\n",
      "Epoch 65/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.6822 - categorical_accuracy: 0.7785 - val_loss: 0.6317 - val_categorical_accuracy: 0.7797\n",
      "Epoch 66/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.6804 - categorical_accuracy: 0.7777 - val_loss: 0.6309 - val_categorical_accuracy: 0.7752\n",
      "Epoch 67/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.7004 - categorical_accuracy: 0.7713 - val_loss: 0.6689 - val_categorical_accuracy: 0.7749\n",
      "Epoch 68/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.6715 - categorical_accuracy: 0.7799 - val_loss: 0.8236 - val_categorical_accuracy: 0.7695\n",
      "Epoch 69/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.7344 - categorical_accuracy: 0.7595 - val_loss: 0.4871 - val_categorical_accuracy: 0.7675\n",
      "Epoch 70/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.6867 - categorical_accuracy: 0.7774 - val_loss: 0.6649 - val_categorical_accuracy: 0.7693\n",
      "Epoch 71/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.6666 - categorical_accuracy: 0.7819 - val_loss: 0.6214 - val_categorical_accuracy: 0.7773\n",
      "Epoch 72/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.6607 - categorical_accuracy: 0.7833 - val_loss: 0.4652 - val_categorical_accuracy: 0.7779\n",
      "Epoch 73/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.6643 - categorical_accuracy: 0.7817 - val_loss: 0.5978 - val_categorical_accuracy: 0.7773\n",
      "Epoch 74/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.6716 - categorical_accuracy: 0.7817 - val_loss: 0.6451 - val_categorical_accuracy: 0.7779\n",
      "Epoch 75/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.6681 - categorical_accuracy: 0.7833 - val_loss: 0.7154 - val_categorical_accuracy: 0.7760\n",
      "Epoch 76/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.6553 - categorical_accuracy: 0.7858 - val_loss: 0.5275 - val_categorical_accuracy: 0.7848\n",
      "Epoch 77/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.6499 - categorical_accuracy: 0.7861 - val_loss: 0.7422 - val_categorical_accuracy: 0.7844\n",
      "Epoch 78/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.6463 - categorical_accuracy: 0.7884 - val_loss: 0.6997 - val_categorical_accuracy: 0.7832\n",
      "Epoch 79/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.6518 - categorical_accuracy: 0.7869 - val_loss: 0.7443 - val_categorical_accuracy: 0.7804\n",
      "Epoch 80/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.6498 - categorical_accuracy: 0.7889 - val_loss: 0.6227 - val_categorical_accuracy: 0.7831\n",
      "Epoch 81/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.6519 - categorical_accuracy: 0.7872 - val_loss: 0.5640 - val_categorical_accuracy: 0.7903\n",
      "Epoch 82/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.6595 - categorical_accuracy: 0.7850 - val_loss: 0.7970 - val_categorical_accuracy: 0.7836\n",
      "Epoch 83/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.6431 - categorical_accuracy: 0.7890 - val_loss: 0.7352 - val_categorical_accuracy: 0.7879\n",
      "Epoch 84/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.6423 - categorical_accuracy: 0.7900 - val_loss: 0.8332 - val_categorical_accuracy: 0.7683\n",
      "Epoch 85/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.6560 - categorical_accuracy: 0.7861 - val_loss: 0.7978 - val_categorical_accuracy: 0.7871\n",
      "Epoch 86/400\n",
      "167/167 [==============================] - 58s 350ms/step - loss: 0.6591 - categorical_accuracy: 0.7865 - val_loss: 0.4370 - val_categorical_accuracy: 0.7909\n",
      "Epoch 87/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.6436 - categorical_accuracy: 0.7903 - val_loss: 0.7225 - val_categorical_accuracy: 0.7821\n",
      "Epoch 88/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.6805 - categorical_accuracy: 0.7821 - val_loss: 0.7531 - val_categorical_accuracy: 0.7884\n",
      "Epoch 89/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.6497 - categorical_accuracy: 0.7869 - val_loss: 0.7221 - val_categorical_accuracy: 0.7804\n",
      "Epoch 90/400\n",
      "167/167 [==============================] - 57s 343ms/step - loss: 0.6391 - categorical_accuracy: 0.7940 - val_loss: 0.8472 - val_categorical_accuracy: 0.7788\n",
      "Epoch 91/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.6353 - categorical_accuracy: 0.7909 - val_loss: 0.7763 - val_categorical_accuracy: 0.7813\n",
      "Epoch 92/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.6413 - categorical_accuracy: 0.7911 - val_loss: 0.7937 - val_categorical_accuracy: 0.7797\n",
      "Epoch 93/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.6375 - categorical_accuracy: 0.7923 - val_loss: 0.6515 - val_categorical_accuracy: 0.7825\n",
      "Epoch 94/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.6413 - categorical_accuracy: 0.7902 - val_loss: 0.7705 - val_categorical_accuracy: 0.7843\n",
      "Epoch 95/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.6289 - categorical_accuracy: 0.7937 - val_loss: 0.7425 - val_categorical_accuracy: 0.7869\n",
      "Epoch 96/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.6283 - categorical_accuracy: 0.7949 - val_loss: 0.5322 - val_categorical_accuracy: 0.7865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.6395 - categorical_accuracy: 0.7926 - val_loss: 0.6104 - val_categorical_accuracy: 0.7924\n",
      "Epoch 98/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.6274 - categorical_accuracy: 0.7946 - val_loss: 1.0351 - val_categorical_accuracy: 0.7892\n",
      "Epoch 99/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.6210 - categorical_accuracy: 0.7982 - val_loss: 0.6094 - val_categorical_accuracy: 0.7912\n",
      "Epoch 100/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.6241 - categorical_accuracy: 0.7968 - val_loss: 0.7018 - val_categorical_accuracy: 0.7877\n",
      "Epoch 101/400\n",
      "167/167 [==============================] - 58s 350ms/step - loss: 0.6302 - categorical_accuracy: 0.7953 - val_loss: 0.5516 - val_categorical_accuracy: 0.7856\n",
      "Epoch 102/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.6254 - categorical_accuracy: 0.7965 - val_loss: 0.6295 - val_categorical_accuracy: 0.7861\n",
      "Epoch 103/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.6245 - categorical_accuracy: 0.7937 - val_loss: 0.8457 - val_categorical_accuracy: 0.7893\n",
      "Epoch 104/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.6188 - categorical_accuracy: 0.7964 - val_loss: 0.6129 - val_categorical_accuracy: 0.7995\n",
      "Epoch 105/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.6302 - categorical_accuracy: 0.7943 - val_loss: 0.6386 - val_categorical_accuracy: 0.7836\n",
      "Epoch 106/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.6228 - categorical_accuracy: 0.7956 - val_loss: 0.6919 - val_categorical_accuracy: 0.7916\n",
      "Epoch 107/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.6224 - categorical_accuracy: 0.7974 - val_loss: 0.6235 - val_categorical_accuracy: 0.7833\n",
      "Epoch 108/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.6216 - categorical_accuracy: 0.7972 - val_loss: 0.4277 - val_categorical_accuracy: 0.7879\n",
      "Epoch 109/400\n",
      "167/167 [==============================] - 57s 343ms/step - loss: 0.6213 - categorical_accuracy: 0.7984 - val_loss: 0.6572 - val_categorical_accuracy: 0.7845\n",
      "Epoch 110/400\n",
      "167/167 [==============================] - 59s 350ms/step - loss: 0.6139 - categorical_accuracy: 0.8003 - val_loss: 0.8915 - val_categorical_accuracy: 0.7717\n",
      "Epoch 111/400\n",
      "167/167 [==============================] - 58s 350ms/step - loss: 0.6241 - categorical_accuracy: 0.7993 - val_loss: 0.5364 - val_categorical_accuracy: 0.7937\n",
      "Epoch 112/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.6273 - categorical_accuracy: 0.7984 - val_loss: 0.7092 - val_categorical_accuracy: 0.7941\n",
      "Epoch 113/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.6244 - categorical_accuracy: 0.7966 - val_loss: 0.6935 - val_categorical_accuracy: 0.7975\n",
      "Epoch 114/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.6123 - categorical_accuracy: 0.7998 - val_loss: 0.9836 - val_categorical_accuracy: 0.7920\n",
      "Epoch 115/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.6369 - categorical_accuracy: 0.7922 - val_loss: 0.5192 - val_categorical_accuracy: 0.7928\n",
      "Epoch 116/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.6111 - categorical_accuracy: 0.7989 - val_loss: 0.5029 - val_categorical_accuracy: 0.7892\n",
      "Epoch 117/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.6105 - categorical_accuracy: 0.8005 - val_loss: 0.5224 - val_categorical_accuracy: 0.7868\n",
      "Epoch 118/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.6312 - categorical_accuracy: 0.7962 - val_loss: 0.4419 - val_categorical_accuracy: 0.7841\n",
      "Epoch 119/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.6142 - categorical_accuracy: 0.8002 - val_loss: 0.3835 - val_categorical_accuracy: 0.7973\n",
      "Epoch 120/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.6232 - categorical_accuracy: 0.8002 - val_loss: 0.7731 - val_categorical_accuracy: 0.7923\n",
      "Epoch 121/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5997 - categorical_accuracy: 0.8057 - val_loss: 0.4769 - val_categorical_accuracy: 0.8025\n",
      "Epoch 122/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.6314 - categorical_accuracy: 0.7967 - val_loss: 0.8065 - val_categorical_accuracy: 0.7949\n",
      "Epoch 123/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.6058 - categorical_accuracy: 0.8011 - val_loss: 0.6870 - val_categorical_accuracy: 0.7979\n",
      "Epoch 124/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.6267 - categorical_accuracy: 0.7992 - val_loss: 0.4826 - val_categorical_accuracy: 0.7949\n",
      "Epoch 125/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.6080 - categorical_accuracy: 0.8017 - val_loss: 0.8715 - val_categorical_accuracy: 0.7977\n",
      "Epoch 126/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5985 - categorical_accuracy: 0.8037 - val_loss: 0.4889 - val_categorical_accuracy: 0.7923\n",
      "Epoch 127/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.5973 - categorical_accuracy: 0.8056 - val_loss: 0.5056 - val_categorical_accuracy: 0.8013\n",
      "Epoch 128/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.6076 - categorical_accuracy: 0.8025 - val_loss: 0.7087 - val_categorical_accuracy: 0.7913\n",
      "Epoch 129/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.6073 - categorical_accuracy: 0.8031 - val_loss: 0.6204 - val_categorical_accuracy: 0.8003\n",
      "Epoch 130/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.6073 - categorical_accuracy: 0.8025 - val_loss: 0.7914 - val_categorical_accuracy: 0.7988\n",
      "Epoch 131/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5950 - categorical_accuracy: 0.8069 - val_loss: 0.7024 - val_categorical_accuracy: 0.7991\n",
      "Epoch 132/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.6085 - categorical_accuracy: 0.8017 - val_loss: 0.7067 - val_categorical_accuracy: 0.7935\n",
      "Epoch 133/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.6163 - categorical_accuracy: 0.8006 - val_loss: 0.6093 - val_categorical_accuracy: 0.7993\n",
      "Epoch 134/400\n",
      "167/167 [==============================] - 58s 350ms/step - loss: 0.5897 - categorical_accuracy: 0.8060 - val_loss: 0.5506 - val_categorical_accuracy: 0.7984\n",
      "Epoch 135/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.6185 - categorical_accuracy: 0.7985 - val_loss: 0.5494 - val_categorical_accuracy: 0.7945\n",
      "Epoch 136/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.6097 - categorical_accuracy: 0.8004 - val_loss: 0.6329 - val_categorical_accuracy: 0.7969\n",
      "Epoch 137/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.6037 - categorical_accuracy: 0.8016 - val_loss: 0.6049 - val_categorical_accuracy: 0.8025\n",
      "Epoch 138/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.6132 - categorical_accuracy: 0.7997 - val_loss: 0.7712 - val_categorical_accuracy: 0.7907\n",
      "Epoch 139/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5893 - categorical_accuracy: 0.8076 - val_loss: 0.4972 - val_categorical_accuracy: 0.8029\n",
      "Epoch 140/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.6267 - categorical_accuracy: 0.7970 - val_loss: 0.7736 - val_categorical_accuracy: 0.7921\n",
      "Epoch 141/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.6019 - categorical_accuracy: 0.8023 - val_loss: 0.6742 - val_categorical_accuracy: 0.7975\n",
      "Epoch 142/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.6002 - categorical_accuracy: 0.8040 - val_loss: 0.7055 - val_categorical_accuracy: 0.7935\n",
      "Epoch 143/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.6051 - categorical_accuracy: 0.8041 - val_loss: 0.6763 - val_categorical_accuracy: 0.8021\n",
      "Epoch 144/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5867 - categorical_accuracy: 0.8096 - val_loss: 0.2922 - val_categorical_accuracy: 0.7948\n",
      "Epoch 145/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5939 - categorical_accuracy: 0.8072 - val_loss: 0.5114 - val_categorical_accuracy: 0.7985\n",
      "Epoch 146/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.6127 - categorical_accuracy: 0.8016 - val_loss: 0.7172 - val_categorical_accuracy: 0.7977\n",
      "Epoch 147/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5999 - categorical_accuracy: 0.8055 - val_loss: 0.7874 - val_categorical_accuracy: 0.7941\n",
      "Epoch 148/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5941 - categorical_accuracy: 0.8067 - val_loss: 0.8118 - val_categorical_accuracy: 0.7971\n",
      "Epoch 149/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5932 - categorical_accuracy: 0.8060 - val_loss: 0.6519 - val_categorical_accuracy: 0.8027\n",
      "Epoch 150/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.6198 - categorical_accuracy: 0.8017 - val_loss: 0.9234 - val_categorical_accuracy: 0.7940\n",
      "Epoch 151/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5972 - categorical_accuracy: 0.8050 - val_loss: 0.6344 - val_categorical_accuracy: 0.8017\n",
      "Epoch 152/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5936 - categorical_accuracy: 0.8058 - val_loss: 0.4504 - val_categorical_accuracy: 0.8015\n",
      "Epoch 153/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5879 - categorical_accuracy: 0.8096 - val_loss: 0.7698 - val_categorical_accuracy: 0.8040\n",
      "Epoch 154/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.6095 - categorical_accuracy: 0.8001 - val_loss: 0.6873 - val_categorical_accuracy: 0.8012\n",
      "Epoch 155/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5875 - categorical_accuracy: 0.8074 - val_loss: 0.7335 - val_categorical_accuracy: 0.8047\n",
      "Epoch 156/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5807 - categorical_accuracy: 0.8122 - val_loss: 0.6976 - val_categorical_accuracy: 0.8031\n",
      "Epoch 157/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5772 - categorical_accuracy: 0.8123 - val_loss: 0.6036 - val_categorical_accuracy: 0.8061\n",
      "Epoch 158/400\n",
      "167/167 [==============================] - 58s 344ms/step - loss: 0.6030 - categorical_accuracy: 0.8052 - val_loss: 0.6336 - val_categorical_accuracy: 0.7969\n",
      "Epoch 159/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5793 - categorical_accuracy: 0.8107 - val_loss: 0.4379 - val_categorical_accuracy: 0.8013\n",
      "Epoch 160/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5936 - categorical_accuracy: 0.8069 - val_loss: 0.6993 - val_categorical_accuracy: 0.8027\n",
      "Epoch 161/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5903 - categorical_accuracy: 0.8075 - val_loss: 0.5903 - val_categorical_accuracy: 0.7872\n",
      "Epoch 162/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5918 - categorical_accuracy: 0.8080 - val_loss: 0.6892 - val_categorical_accuracy: 0.8068\n",
      "Epoch 163/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5992 - categorical_accuracy: 0.8063 - val_loss: 0.5242 - val_categorical_accuracy: 0.8075\n",
      "Epoch 164/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5817 - categorical_accuracy: 0.8113 - val_loss: 0.4750 - val_categorical_accuracy: 0.7607\n",
      "Epoch 165/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.6115 - categorical_accuracy: 0.8017 - val_loss: 0.8657 - val_categorical_accuracy: 0.7968\n",
      "Epoch 166/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5936 - categorical_accuracy: 0.8079 - val_loss: 0.5255 - val_categorical_accuracy: 0.8075\n",
      "Epoch 167/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5813 - categorical_accuracy: 0.8125 - val_loss: 0.7427 - val_categorical_accuracy: 0.7995\n",
      "Epoch 168/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5888 - categorical_accuracy: 0.8112 - val_loss: 0.6342 - val_categorical_accuracy: 0.8055\n",
      "Epoch 169/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5826 - categorical_accuracy: 0.8107 - val_loss: 0.4756 - val_categorical_accuracy: 0.7987\n",
      "Epoch 170/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5910 - categorical_accuracy: 0.8121 - val_loss: 0.5441 - val_categorical_accuracy: 0.7957\n",
      "Epoch 171/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5812 - categorical_accuracy: 0.8112 - val_loss: 0.5915 - val_categorical_accuracy: 0.8015\n",
      "Epoch 172/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5801 - categorical_accuracy: 0.8123 - val_loss: 0.7306 - val_categorical_accuracy: 0.8040\n",
      "Epoch 173/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5722 - categorical_accuracy: 0.8144 - val_loss: 0.7415 - val_categorical_accuracy: 0.8068\n",
      "Epoch 174/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5685 - categorical_accuracy: 0.8141 - val_loss: 0.8922 - val_categorical_accuracy: 0.8009\n",
      "Epoch 175/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5762 - categorical_accuracy: 0.8121 - val_loss: 0.5920 - val_categorical_accuracy: 0.7971\n",
      "Epoch 176/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5860 - categorical_accuracy: 0.8094 - val_loss: 0.4171 - val_categorical_accuracy: 0.7964\n",
      "Epoch 177/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.6057 - categorical_accuracy: 0.8032 - val_loss: 0.6220 - val_categorical_accuracy: 0.8037\n",
      "Epoch 178/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5808 - categorical_accuracy: 0.8108 - val_loss: 0.6417 - val_categorical_accuracy: 0.8056\n",
      "Epoch 179/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5739 - categorical_accuracy: 0.8122 - val_loss: 0.4367 - val_categorical_accuracy: 0.7999\n",
      "Epoch 180/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.6005 - categorical_accuracy: 0.8047 - val_loss: 0.5589 - val_categorical_accuracy: 0.7987\n",
      "Epoch 181/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5754 - categorical_accuracy: 0.8127 - val_loss: 0.7321 - val_categorical_accuracy: 0.8045\n",
      "Epoch 182/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5709 - categorical_accuracy: 0.8148 - val_loss: 0.6772 - val_categorical_accuracy: 0.8067\n",
      "Epoch 183/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5734 - categorical_accuracy: 0.8124 - val_loss: 0.5725 - val_categorical_accuracy: 0.8028\n",
      "Epoch 184/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5690 - categorical_accuracy: 0.8141 - val_loss: 0.8900 - val_categorical_accuracy: 0.8077\n",
      "Epoch 185/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5796 - categorical_accuracy: 0.8144 - val_loss: 0.6441 - val_categorical_accuracy: 0.8056\n",
      "Epoch 186/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5807 - categorical_accuracy: 0.8121 - val_loss: 0.8161 - val_categorical_accuracy: 0.8051\n",
      "Epoch 187/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5776 - categorical_accuracy: 0.8131 - val_loss: 0.6119 - val_categorical_accuracy: 0.8053\n",
      "Epoch 188/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5702 - categorical_accuracy: 0.8135 - val_loss: 0.6274 - val_categorical_accuracy: 0.8016\n",
      "Epoch 189/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5644 - categorical_accuracy: 0.8140 - val_loss: 0.5783 - val_categorical_accuracy: 0.8032\n",
      "Epoch 190/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5760 - categorical_accuracy: 0.8135 - val_loss: 0.6178 - val_categorical_accuracy: 0.8013\n",
      "Epoch 191/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5607 - categorical_accuracy: 0.8173 - val_loss: 0.7781 - val_categorical_accuracy: 0.8031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.6025 - categorical_accuracy: 0.8067 - val_loss: 0.7467 - val_categorical_accuracy: 0.7921\n",
      "Epoch 193/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5762 - categorical_accuracy: 0.8146 - val_loss: 0.6312 - val_categorical_accuracy: 0.7827\n",
      "Epoch 194/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5793 - categorical_accuracy: 0.8139 - val_loss: 0.6620 - val_categorical_accuracy: 0.8080\n",
      "Epoch 195/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.5712 - categorical_accuracy: 0.8153 - val_loss: 0.7239 - val_categorical_accuracy: 0.8168\n",
      "Epoch 196/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5653 - categorical_accuracy: 0.8156 - val_loss: 0.5502 - val_categorical_accuracy: 0.8087\n",
      "Epoch 197/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5717 - categorical_accuracy: 0.8139 - val_loss: 0.6479 - val_categorical_accuracy: 0.8029\n",
      "Epoch 198/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5780 - categorical_accuracy: 0.8137 - val_loss: 0.6999 - val_categorical_accuracy: 0.8083\n",
      "Epoch 199/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5677 - categorical_accuracy: 0.8142 - val_loss: 0.5609 - val_categorical_accuracy: 0.8077\n",
      "Epoch 200/400\n",
      "167/167 [==============================] - 57s 344ms/step - loss: 0.5738 - categorical_accuracy: 0.8136 - val_loss: 0.6126 - val_categorical_accuracy: 0.7736\n",
      "Epoch 201/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.6002 - categorical_accuracy: 0.8051 - val_loss: 0.6441 - val_categorical_accuracy: 0.8044\n",
      "Epoch 202/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5800 - categorical_accuracy: 0.8125 - val_loss: 0.6056 - val_categorical_accuracy: 0.8067\n",
      "Epoch 203/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5654 - categorical_accuracy: 0.8135 - val_loss: 0.6627 - val_categorical_accuracy: 0.8053\n",
      "Epoch 204/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5623 - categorical_accuracy: 0.8144 - val_loss: 0.5171 - val_categorical_accuracy: 0.8101\n",
      "Epoch 205/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5703 - categorical_accuracy: 0.8136 - val_loss: 0.6528 - val_categorical_accuracy: 0.8059\n",
      "Epoch 206/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5704 - categorical_accuracy: 0.8168 - val_loss: 0.4370 - val_categorical_accuracy: 0.8147\n",
      "Epoch 207/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5656 - categorical_accuracy: 0.8170 - val_loss: 0.7496 - val_categorical_accuracy: 0.8112\n",
      "Epoch 208/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5616 - categorical_accuracy: 0.8186 - val_loss: 0.3845 - val_categorical_accuracy: 0.8096\n",
      "Epoch 209/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5620 - categorical_accuracy: 0.8184 - val_loss: 0.6185 - val_categorical_accuracy: 0.8000\n",
      "Epoch 210/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5596 - categorical_accuracy: 0.8172 - val_loss: 0.5875 - val_categorical_accuracy: 0.8073\n",
      "Epoch 211/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5606 - categorical_accuracy: 0.8191 - val_loss: 0.5226 - val_categorical_accuracy: 0.8044\n",
      "Epoch 212/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5800 - categorical_accuracy: 0.8124 - val_loss: 0.7544 - val_categorical_accuracy: 0.8059\n",
      "Epoch 213/400\n",
      "167/167 [==============================] - 57s 343ms/step - loss: 0.5638 - categorical_accuracy: 0.8159 - val_loss: 0.5716 - val_categorical_accuracy: 0.8091\n",
      "Epoch 214/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.6049 - categorical_accuracy: 0.8034 - val_loss: 0.6705 - val_categorical_accuracy: 0.8075\n",
      "Epoch 215/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5788 - categorical_accuracy: 0.8109 - val_loss: 0.4552 - val_categorical_accuracy: 0.8091\n",
      "Epoch 216/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5628 - categorical_accuracy: 0.8172 - val_loss: 0.5762 - val_categorical_accuracy: 0.8088\n",
      "Epoch 217/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5670 - categorical_accuracy: 0.8153 - val_loss: 0.5854 - val_categorical_accuracy: 0.8053\n",
      "Epoch 218/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5709 - categorical_accuracy: 0.8130 - val_loss: 0.7958 - val_categorical_accuracy: 0.8100\n",
      "Epoch 219/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5585 - categorical_accuracy: 0.8165 - val_loss: 0.6545 - val_categorical_accuracy: 0.8060\n",
      "Epoch 220/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5607 - categorical_accuracy: 0.8168 - val_loss: 0.5794 - val_categorical_accuracy: 0.7996\n",
      "Epoch 221/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5642 - categorical_accuracy: 0.8174 - val_loss: 0.5265 - val_categorical_accuracy: 0.8081\n",
      "Epoch 222/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.5660 - categorical_accuracy: 0.8172 - val_loss: 0.7247 - val_categorical_accuracy: 0.8069\n",
      "Epoch 223/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5623 - categorical_accuracy: 0.8157 - val_loss: 0.5575 - val_categorical_accuracy: 0.8112\n",
      "Epoch 224/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5590 - categorical_accuracy: 0.8163 - val_loss: 0.3829 - val_categorical_accuracy: 0.8127\n",
      "Epoch 225/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5514 - categorical_accuracy: 0.8201 - val_loss: 0.8497 - val_categorical_accuracy: 0.8057\n",
      "Epoch 226/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.5706 - categorical_accuracy: 0.8162 - val_loss: 0.4997 - val_categorical_accuracy: 0.8016\n",
      "Epoch 227/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5579 - categorical_accuracy: 0.8197 - val_loss: 0.4935 - val_categorical_accuracy: 0.8108\n",
      "Epoch 228/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5574 - categorical_accuracy: 0.8182 - val_loss: 0.5592 - val_categorical_accuracy: 0.8097\n",
      "Epoch 229/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5613 - categorical_accuracy: 0.8191 - val_loss: 0.7222 - val_categorical_accuracy: 0.8075\n",
      "Epoch 230/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.5710 - categorical_accuracy: 0.8153 - val_loss: 0.5613 - val_categorical_accuracy: 0.8089\n",
      "Epoch 231/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5582 - categorical_accuracy: 0.8186 - val_loss: 0.5118 - val_categorical_accuracy: 0.8025\n",
      "Epoch 232/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5567 - categorical_accuracy: 0.8189 - val_loss: 0.6069 - val_categorical_accuracy: 0.8096\n",
      "Epoch 233/400\n",
      "167/167 [==============================] - 59s 351ms/step - loss: 0.5525 - categorical_accuracy: 0.8205 - val_loss: 0.7988 - val_categorical_accuracy: 0.8057\n",
      "Epoch 234/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5574 - categorical_accuracy: 0.8180 - val_loss: 0.5927 - val_categorical_accuracy: 0.8117\n",
      "Epoch 235/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5756 - categorical_accuracy: 0.8098 - val_loss: 0.6162 - val_categorical_accuracy: 0.8085\n",
      "Epoch 236/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.5583 - categorical_accuracy: 0.8194 - val_loss: 0.5544 - val_categorical_accuracy: 0.8055\n",
      "Epoch 237/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5534 - categorical_accuracy: 0.8205 - val_loss: 0.6136 - val_categorical_accuracy: 0.8148\n",
      "Epoch 238/400\n",
      "167/167 [==============================] - 58s 350ms/step - loss: 0.5627 - categorical_accuracy: 0.8185 - val_loss: 0.6061 - val_categorical_accuracy: 0.8159\n",
      "Epoch 239/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5656 - categorical_accuracy: 0.8178 - val_loss: 0.5594 - val_categorical_accuracy: 0.8089\n",
      "Epoch 240/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5516 - categorical_accuracy: 0.8204 - val_loss: 0.4638 - val_categorical_accuracy: 0.8187\n",
      "Epoch 241/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.5554 - categorical_accuracy: 0.8194 - val_loss: 0.5488 - val_categorical_accuracy: 0.8101\n",
      "Epoch 242/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.5520 - categorical_accuracy: 0.8198 - val_loss: 0.6654 - val_categorical_accuracy: 0.8159\n",
      "Epoch 243/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5504 - categorical_accuracy: 0.8196 - val_loss: 0.6194 - val_categorical_accuracy: 0.8193\n",
      "Epoch 244/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.5525 - categorical_accuracy: 0.8200 - val_loss: 0.6958 - val_categorical_accuracy: 0.8131\n",
      "Epoch 245/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.5737 - categorical_accuracy: 0.8156 - val_loss: 0.4981 - val_categorical_accuracy: 0.8151\n",
      "Epoch 246/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5626 - categorical_accuracy: 0.8176 - val_loss: 0.8160 - val_categorical_accuracy: 0.8083\n",
      "Epoch 247/400\n",
      "167/167 [==============================] - 58s 350ms/step - loss: 0.5519 - categorical_accuracy: 0.8213 - val_loss: 0.6550 - val_categorical_accuracy: 0.8109\n",
      "Epoch 248/400\n",
      "167/167 [==============================] - 59s 351ms/step - loss: 0.5562 - categorical_accuracy: 0.8191 - val_loss: 0.4648 - val_categorical_accuracy: 0.8065\n",
      "Epoch 249/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5529 - categorical_accuracy: 0.8192 - val_loss: 0.6928 - val_categorical_accuracy: 0.8155\n",
      "Epoch 250/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.6001 - categorical_accuracy: 0.8056 - val_loss: 0.5367 - val_categorical_accuracy: 0.8065\n",
      "Epoch 251/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5552 - categorical_accuracy: 0.8190 - val_loss: 0.5843 - val_categorical_accuracy: 0.8100\n",
      "Epoch 252/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5595 - categorical_accuracy: 0.8178 - val_loss: 0.6894 - val_categorical_accuracy: 0.8023\n",
      "Epoch 253/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5681 - categorical_accuracy: 0.8183 - val_loss: 0.6707 - val_categorical_accuracy: 0.8037\n",
      "Epoch 254/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5585 - categorical_accuracy: 0.8176 - val_loss: 0.6106 - val_categorical_accuracy: 0.8151\n",
      "Epoch 255/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5662 - categorical_accuracy: 0.8192 - val_loss: 0.6874 - val_categorical_accuracy: 0.8065\n",
      "Epoch 256/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5480 - categorical_accuracy: 0.8225 - val_loss: 0.4233 - val_categorical_accuracy: 0.8151\n",
      "Epoch 257/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5512 - categorical_accuracy: 0.8199 - val_loss: 0.5614 - val_categorical_accuracy: 0.8053\n",
      "Epoch 258/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5475 - categorical_accuracy: 0.8233 - val_loss: 0.4655 - val_categorical_accuracy: 0.8049\n",
      "Epoch 259/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5546 - categorical_accuracy: 0.8215 - val_loss: 0.5798 - val_categorical_accuracy: 0.8183\n",
      "Epoch 260/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5806 - categorical_accuracy: 0.8146 - val_loss: 0.3531 - val_categorical_accuracy: 0.8061\n",
      "Epoch 261/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5553 - categorical_accuracy: 0.8207 - val_loss: 0.4578 - val_categorical_accuracy: 0.8136\n",
      "Epoch 262/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5567 - categorical_accuracy: 0.8205 - val_loss: 0.5029 - val_categorical_accuracy: 0.7863\n",
      "Epoch 263/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5559 - categorical_accuracy: 0.8187 - val_loss: 0.6941 - val_categorical_accuracy: 0.8039\n",
      "Epoch 264/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5534 - categorical_accuracy: 0.8179 - val_loss: 0.5034 - val_categorical_accuracy: 0.8105\n",
      "Epoch 265/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5442 - categorical_accuracy: 0.8209 - val_loss: 0.7270 - val_categorical_accuracy: 0.8165\n",
      "Epoch 266/400\n",
      "167/167 [==============================] - 57s 344ms/step - loss: 0.5454 - categorical_accuracy: 0.8211 - val_loss: 0.4972 - val_categorical_accuracy: 0.8096\n",
      "Epoch 267/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5443 - categorical_accuracy: 0.8223 - val_loss: 0.5891 - val_categorical_accuracy: 0.8071\n",
      "Epoch 268/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5487 - categorical_accuracy: 0.8198 - val_loss: 0.5957 - val_categorical_accuracy: 0.8091\n",
      "Epoch 269/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.5475 - categorical_accuracy: 0.8217 - val_loss: 0.6568 - val_categorical_accuracy: 0.8143\n",
      "Epoch 270/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5535 - categorical_accuracy: 0.8194 - val_loss: 0.6034 - val_categorical_accuracy: 0.8135\n",
      "Epoch 271/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.5525 - categorical_accuracy: 0.8235 - val_loss: 0.4728 - val_categorical_accuracy: 0.7969\n",
      "Epoch 272/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5619 - categorical_accuracy: 0.8187 - val_loss: 0.6344 - val_categorical_accuracy: 0.8157\n",
      "Epoch 273/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5471 - categorical_accuracy: 0.8220 - val_loss: 0.5022 - val_categorical_accuracy: 0.8173\n",
      "Epoch 274/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5518 - categorical_accuracy: 0.8200 - val_loss: 0.5715 - val_categorical_accuracy: 0.8132\n",
      "Epoch 275/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5573 - categorical_accuracy: 0.8189 - val_loss: 0.6229 - val_categorical_accuracy: 0.8087\n",
      "Epoch 276/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5668 - categorical_accuracy: 0.8209 - val_loss: 0.5625 - val_categorical_accuracy: 0.8048\n",
      "Epoch 277/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5501 - categorical_accuracy: 0.8202 - val_loss: 0.6409 - val_categorical_accuracy: 0.8147\n",
      "Epoch 278/400\n",
      "167/167 [==============================] - 57s 344ms/step - loss: 0.5414 - categorical_accuracy: 0.8225 - val_loss: 0.5410 - val_categorical_accuracy: 0.8131\n",
      "Epoch 279/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5450 - categorical_accuracy: 0.8226 - val_loss: 0.6296 - val_categorical_accuracy: 0.8088\n",
      "Epoch 280/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5529 - categorical_accuracy: 0.8236 - val_loss: 0.7662 - val_categorical_accuracy: 0.8100\n",
      "Epoch 281/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5701 - categorical_accuracy: 0.8176 - val_loss: 0.4566 - val_categorical_accuracy: 0.8144\n",
      "Epoch 282/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5493 - categorical_accuracy: 0.8219 - val_loss: 0.5400 - val_categorical_accuracy: 0.8100\n",
      "Epoch 283/400\n",
      "167/167 [==============================] - 57s 344ms/step - loss: 0.5524 - categorical_accuracy: 0.8228 - val_loss: 0.6093 - val_categorical_accuracy: 0.7933\n",
      "Epoch 284/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5517 - categorical_accuracy: 0.8214 - val_loss: 0.8110 - val_categorical_accuracy: 0.8097\n",
      "Epoch 285/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5381 - categorical_accuracy: 0.8247 - val_loss: 0.4671 - val_categorical_accuracy: 0.8116\n",
      "Epoch 286/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5603 - categorical_accuracy: 0.8207 - val_loss: 0.5557 - val_categorical_accuracy: 0.8176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 287/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5403 - categorical_accuracy: 0.8236 - val_loss: 0.5613 - val_categorical_accuracy: 0.8128\n",
      "Epoch 288/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5545 - categorical_accuracy: 0.8214 - val_loss: 0.7164 - val_categorical_accuracy: 0.8188\n",
      "Epoch 289/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5557 - categorical_accuracy: 0.8213 - val_loss: 0.3938 - val_categorical_accuracy: 0.8193\n",
      "Epoch 290/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.5560 - categorical_accuracy: 0.8190 - val_loss: 0.5734 - val_categorical_accuracy: 0.8143\n",
      "Epoch 291/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5422 - categorical_accuracy: 0.8259 - val_loss: 0.7348 - val_categorical_accuracy: 0.8108\n",
      "Epoch 292/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5488 - categorical_accuracy: 0.8217 - val_loss: 0.4571 - val_categorical_accuracy: 0.8135\n",
      "Epoch 293/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5696 - categorical_accuracy: 0.8169 - val_loss: 0.4303 - val_categorical_accuracy: 0.8136\n",
      "Epoch 294/400\n",
      "167/167 [==============================] - 57s 344ms/step - loss: 0.5452 - categorical_accuracy: 0.8244 - val_loss: 0.4950 - val_categorical_accuracy: 0.8164\n",
      "Epoch 295/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5442 - categorical_accuracy: 0.8233 - val_loss: 0.7175 - val_categorical_accuracy: 0.7767\n",
      "Epoch 296/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5466 - categorical_accuracy: 0.8231 - val_loss: 0.6573 - val_categorical_accuracy: 0.8204\n",
      "Epoch 297/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5405 - categorical_accuracy: 0.8227 - val_loss: 0.6254 - val_categorical_accuracy: 0.8105\n",
      "Epoch 298/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5377 - categorical_accuracy: 0.8250 - val_loss: 0.7159 - val_categorical_accuracy: 0.8160\n",
      "Epoch 299/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5350 - categorical_accuracy: 0.8253 - val_loss: 0.7481 - val_categorical_accuracy: 0.8167\n",
      "Epoch 300/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5352 - categorical_accuracy: 0.8254 - val_loss: 0.5654 - val_categorical_accuracy: 0.8116\n",
      "Epoch 301/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5545 - categorical_accuracy: 0.8196 - val_loss: 0.7090 - val_categorical_accuracy: 0.8131\n",
      "Epoch 302/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.5439 - categorical_accuracy: 0.8199 - val_loss: 0.6007 - val_categorical_accuracy: 0.8133\n",
      "Epoch 303/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5467 - categorical_accuracy: 0.8216 - val_loss: 0.6434 - val_categorical_accuracy: 0.8107\n",
      "Epoch 304/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5574 - categorical_accuracy: 0.8196 - val_loss: 0.3073 - val_categorical_accuracy: 0.8113\n",
      "Epoch 305/400\n",
      "167/167 [==============================] - 57s 343ms/step - loss: 0.5468 - categorical_accuracy: 0.8227 - val_loss: 0.5886 - val_categorical_accuracy: 0.8137\n",
      "Epoch 306/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5686 - categorical_accuracy: 0.8188 - val_loss: 0.9818 - val_categorical_accuracy: 0.8043\n",
      "Epoch 307/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5525 - categorical_accuracy: 0.8202 - val_loss: 0.4610 - val_categorical_accuracy: 0.8197\n",
      "Epoch 308/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.5392 - categorical_accuracy: 0.8252 - val_loss: 0.5437 - val_categorical_accuracy: 0.8099\n",
      "Epoch 309/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5477 - categorical_accuracy: 0.8219 - val_loss: 0.6953 - val_categorical_accuracy: 0.8177\n",
      "Epoch 310/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5405 - categorical_accuracy: 0.8235 - val_loss: 0.4729 - val_categorical_accuracy: 0.8121\n",
      "Epoch 311/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5506 - categorical_accuracy: 0.8213 - val_loss: 0.6563 - val_categorical_accuracy: 0.8155\n",
      "Epoch 312/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5439 - categorical_accuracy: 0.8254 - val_loss: 0.5033 - val_categorical_accuracy: 0.8181\n",
      "Epoch 313/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5348 - categorical_accuracy: 0.8248 - val_loss: 0.5970 - val_categorical_accuracy: 0.8125\n",
      "Epoch 314/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5320 - categorical_accuracy: 0.8281 - val_loss: 0.7049 - val_categorical_accuracy: 0.8212\n",
      "Epoch 315/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5451 - categorical_accuracy: 0.8242 - val_loss: 0.5900 - val_categorical_accuracy: 0.8163\n",
      "Epoch 316/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5352 - categorical_accuracy: 0.8254 - val_loss: 0.4149 - val_categorical_accuracy: 0.8069\n",
      "Epoch 317/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5517 - categorical_accuracy: 0.8255 - val_loss: 0.6040 - val_categorical_accuracy: 0.7552\n",
      "Epoch 318/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.5571 - categorical_accuracy: 0.8187 - val_loss: 0.5103 - val_categorical_accuracy: 0.8139\n",
      "Epoch 319/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5434 - categorical_accuracy: 0.8241 - val_loss: 0.4752 - val_categorical_accuracy: 0.8107\n",
      "Epoch 320/400\n",
      "167/167 [==============================] - 57s 344ms/step - loss: 0.5414 - categorical_accuracy: 0.8239 - val_loss: 0.6722 - val_categorical_accuracy: 0.8161\n",
      "Epoch 321/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5358 - categorical_accuracy: 0.8267 - val_loss: 0.8193 - val_categorical_accuracy: 0.8187\n",
      "Epoch 322/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5485 - categorical_accuracy: 0.8205 - val_loss: 0.4099 - val_categorical_accuracy: 0.8215\n",
      "Epoch 323/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5437 - categorical_accuracy: 0.8244 - val_loss: 0.6742 - val_categorical_accuracy: 0.8168\n",
      "Epoch 324/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5477 - categorical_accuracy: 0.8241 - val_loss: 0.5888 - val_categorical_accuracy: 0.8169\n",
      "Epoch 325/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5494 - categorical_accuracy: 0.8207 - val_loss: 0.6164 - val_categorical_accuracy: 0.8203\n",
      "Epoch 326/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5299 - categorical_accuracy: 0.8268 - val_loss: 0.7716 - val_categorical_accuracy: 0.8141\n",
      "Epoch 327/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.5400 - categorical_accuracy: 0.8271 - val_loss: 0.7266 - val_categorical_accuracy: 0.8149\n",
      "Epoch 328/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5410 - categorical_accuracy: 0.8236 - val_loss: 0.8106 - val_categorical_accuracy: 0.8244\n",
      "Epoch 329/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.5378 - categorical_accuracy: 0.8252 - val_loss: 0.3457 - val_categorical_accuracy: 0.8140\n",
      "Epoch 330/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.5521 - categorical_accuracy: 0.8222 - val_loss: 0.5852 - val_categorical_accuracy: 0.8109\n",
      "Epoch 331/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5443 - categorical_accuracy: 0.8237 - val_loss: 0.5062 - val_categorical_accuracy: 0.8152\n",
      "Epoch 332/400\n",
      "167/167 [==============================] - 58s 349ms/step - loss: 0.5379 - categorical_accuracy: 0.8229 - val_loss: 0.6193 - val_categorical_accuracy: 0.8163\n",
      "Epoch 333/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5477 - categorical_accuracy: 0.8229 - val_loss: 0.8240 - val_categorical_accuracy: 0.8148\n",
      "Epoch 334/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5583 - categorical_accuracy: 0.8224 - val_loss: 0.7924 - val_categorical_accuracy: 0.8165\n",
      "Epoch 335/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5481 - categorical_accuracy: 0.8224 - val_loss: 0.6070 - val_categorical_accuracy: 0.8167\n",
      "Epoch 336/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5318 - categorical_accuracy: 0.8261 - val_loss: 0.4604 - val_categorical_accuracy: 0.8165\n",
      "Epoch 337/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5356 - categorical_accuracy: 0.8268 - val_loss: 0.5087 - val_categorical_accuracy: 0.8131\n",
      "Epoch 338/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5438 - categorical_accuracy: 0.8259 - val_loss: 0.4081 - val_categorical_accuracy: 0.8203\n",
      "Epoch 339/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5279 - categorical_accuracy: 0.8287 - val_loss: 0.5759 - val_categorical_accuracy: 0.8168\n",
      "Epoch 340/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5369 - categorical_accuracy: 0.8264 - val_loss: 0.5137 - val_categorical_accuracy: 0.8111\n",
      "Epoch 341/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5428 - categorical_accuracy: 0.8245 - val_loss: 0.6725 - val_categorical_accuracy: 0.8119\n",
      "Epoch 342/400\n",
      "167/167 [==============================] - 57s 344ms/step - loss: 0.5396 - categorical_accuracy: 0.8244 - val_loss: 0.4743 - val_categorical_accuracy: 0.8171\n",
      "Epoch 343/400\n",
      "167/167 [==============================] - 58s 344ms/step - loss: 0.5489 - categorical_accuracy: 0.8242 - val_loss: 0.4684 - val_categorical_accuracy: 0.8197\n",
      "Epoch 344/400\n",
      "167/167 [==============================] - 57s 342ms/step - loss: 0.5342 - categorical_accuracy: 0.8250 - val_loss: 0.6637 - val_categorical_accuracy: 0.8100\n",
      "Epoch 345/400\n",
      "167/167 [==============================] - 57s 344ms/step - loss: 0.5333 - categorical_accuracy: 0.8247 - val_loss: 0.6269 - val_categorical_accuracy: 0.8199\n",
      "Epoch 346/400\n",
      "167/167 [==============================] - 58s 344ms/step - loss: 0.5586 - categorical_accuracy: 0.8221 - val_loss: 0.5256 - val_categorical_accuracy: 0.8157\n",
      "Epoch 347/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5382 - categorical_accuracy: 0.8261 - val_loss: 0.3387 - val_categorical_accuracy: 0.8175\n",
      "Epoch 348/400\n",
      "167/167 [==============================] - 58s 344ms/step - loss: 0.5299 - categorical_accuracy: 0.8284 - val_loss: 0.3724 - val_categorical_accuracy: 0.8184\n",
      "Epoch 349/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5296 - categorical_accuracy: 0.8288 - val_loss: 0.5599 - val_categorical_accuracy: 0.8101\n",
      "Epoch 350/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5307 - categorical_accuracy: 0.8286 - val_loss: 0.5641 - val_categorical_accuracy: 0.8145\n",
      "Epoch 351/400\n",
      "167/167 [==============================] - 58s 344ms/step - loss: 0.5340 - categorical_accuracy: 0.8264 - val_loss: 0.8603 - val_categorical_accuracy: 0.8123\n",
      "Epoch 352/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5347 - categorical_accuracy: 0.8275 - val_loss: 0.6037 - val_categorical_accuracy: 0.8129\n",
      "Epoch 353/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5574 - categorical_accuracy: 0.8200 - val_loss: 0.5452 - val_categorical_accuracy: 0.8092\n",
      "Epoch 354/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5348 - categorical_accuracy: 0.8252 - val_loss: 0.6575 - val_categorical_accuracy: 0.8269\n",
      "Epoch 355/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5233 - categorical_accuracy: 0.8274 - val_loss: 0.8543 - val_categorical_accuracy: 0.8156\n",
      "Epoch 356/400\n",
      "167/167 [==============================] - 57s 343ms/step - loss: 0.5323 - categorical_accuracy: 0.8276 - val_loss: 0.6183 - val_categorical_accuracy: 0.8156\n",
      "Epoch 357/400\n",
      "167/167 [==============================] - 57s 342ms/step - loss: 0.5359 - categorical_accuracy: 0.8275 - val_loss: 0.6613 - val_categorical_accuracy: 0.8215\n",
      "Epoch 358/400\n",
      "167/167 [==============================] - 57s 341ms/step - loss: 0.5472 - categorical_accuracy: 0.8248 - val_loss: 0.3779 - val_categorical_accuracy: 0.8165\n",
      "Epoch 359/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5373 - categorical_accuracy: 0.8251 - val_loss: 0.5098 - val_categorical_accuracy: 0.8183\n",
      "Epoch 360/400\n",
      "167/167 [==============================] - 57s 343ms/step - loss: 0.5290 - categorical_accuracy: 0.8275 - val_loss: 0.6447 - val_categorical_accuracy: 0.8180\n",
      "Epoch 361/400\n",
      "167/167 [==============================] - 57s 342ms/step - loss: 0.5300 - categorical_accuracy: 0.8275 - val_loss: 0.5383 - val_categorical_accuracy: 0.8175\n",
      "Epoch 362/400\n",
      "167/167 [==============================] - 57s 342ms/step - loss: 0.5253 - categorical_accuracy: 0.8300 - val_loss: 0.7308 - val_categorical_accuracy: 0.8177\n",
      "Epoch 363/400\n",
      "167/167 [==============================] - 57s 342ms/step - loss: 0.5245 - categorical_accuracy: 0.8284 - val_loss: 0.7426 - val_categorical_accuracy: 0.8187\n",
      "Epoch 364/400\n",
      "167/167 [==============================] - 57s 341ms/step - loss: 0.5277 - categorical_accuracy: 0.8266 - val_loss: 0.7023 - val_categorical_accuracy: 0.8131\n",
      "Epoch 365/400\n",
      "167/167 [==============================] - 57s 342ms/step - loss: 0.5303 - categorical_accuracy: 0.8286 - val_loss: 0.5536 - val_categorical_accuracy: 0.8201\n",
      "Epoch 366/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5337 - categorical_accuracy: 0.8262 - val_loss: 0.6986 - val_categorical_accuracy: 0.8164\n",
      "Epoch 367/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5358 - categorical_accuracy: 0.8246 - val_loss: 0.7351 - val_categorical_accuracy: 0.8133\n",
      "Epoch 368/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5362 - categorical_accuracy: 0.8256 - val_loss: 0.7636 - val_categorical_accuracy: 0.8200\n",
      "Epoch 369/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5327 - categorical_accuracy: 0.8281 - val_loss: 0.7611 - val_categorical_accuracy: 0.8163\n",
      "Epoch 370/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5479 - categorical_accuracy: 0.8227 - val_loss: 0.4839 - val_categorical_accuracy: 0.8117\n",
      "Epoch 371/400\n",
      "167/167 [==============================] - 57s 342ms/step - loss: 0.5305 - categorical_accuracy: 0.8295 - val_loss: 0.6231 - val_categorical_accuracy: 0.8213\n",
      "Epoch 372/400\n",
      "167/167 [==============================] - 57s 344ms/step - loss: 0.5303 - categorical_accuracy: 0.8286 - val_loss: 0.7013 - val_categorical_accuracy: 0.8161\n",
      "Epoch 373/400\n",
      "167/167 [==============================] - 57s 340ms/step - loss: 0.5600 - categorical_accuracy: 0.8184 - val_loss: 0.4604 - val_categorical_accuracy: 0.8181\n",
      "Epoch 374/400\n",
      "167/167 [==============================] - 57s 342ms/step - loss: 0.5371 - categorical_accuracy: 0.8288 - val_loss: 0.6566 - val_categorical_accuracy: 0.7888\n",
      "Epoch 375/400\n",
      "167/167 [==============================] - 57s 343ms/step - loss: 0.5488 - categorical_accuracy: 0.8203 - val_loss: 0.5988 - val_categorical_accuracy: 0.8139\n",
      "Epoch 376/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5401 - categorical_accuracy: 0.8241 - val_loss: 0.5230 - val_categorical_accuracy: 0.8188\n",
      "Epoch 377/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5267 - categorical_accuracy: 0.8282 - val_loss: 0.6777 - val_categorical_accuracy: 0.8147\n",
      "Epoch 378/400\n",
      "167/167 [==============================] - 57s 343ms/step - loss: 0.5280 - categorical_accuracy: 0.8283 - val_loss: 0.4635 - val_categorical_accuracy: 0.8205\n",
      "Epoch 379/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5436 - categorical_accuracy: 0.8248 - val_loss: 0.4404 - val_categorical_accuracy: 0.8184\n",
      "Epoch 380/400\n",
      "167/167 [==============================] - 58s 348ms/step - loss: 0.5326 - categorical_accuracy: 0.8276 - val_loss: 0.5651 - val_categorical_accuracy: 0.8152\n",
      "Epoch 381/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5435 - categorical_accuracy: 0.8242 - val_loss: 0.4111 - val_categorical_accuracy: 0.8140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 382/400\n",
      "167/167 [==============================] - 57s 343ms/step - loss: 0.5261 - categorical_accuracy: 0.8308 - val_loss: 0.3350 - val_categorical_accuracy: 0.8147\n",
      "Epoch 383/400\n",
      "167/167 [==============================] - 56s 338ms/step - loss: 0.5385 - categorical_accuracy: 0.8255 - val_loss: 0.6193 - val_categorical_accuracy: 0.8196\n",
      "Epoch 384/400\n",
      "167/167 [==============================] - 57s 342ms/step - loss: 0.5353 - categorical_accuracy: 0.8287 - val_loss: 0.5524 - val_categorical_accuracy: 0.7580\n",
      "Epoch 385/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5532 - categorical_accuracy: 0.8199 - val_loss: 0.5051 - val_categorical_accuracy: 0.8116\n",
      "Epoch 386/400\n",
      "167/167 [==============================] - 57s 343ms/step - loss: 0.5339 - categorical_accuracy: 0.8292 - val_loss: 0.6331 - val_categorical_accuracy: 0.8163\n",
      "Epoch 387/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5221 - categorical_accuracy: 0.8298 - val_loss: 0.6662 - val_categorical_accuracy: 0.8177\n",
      "Epoch 388/400\n",
      "167/167 [==============================] - 57s 343ms/step - loss: 0.5236 - categorical_accuracy: 0.8304 - val_loss: 0.8669 - val_categorical_accuracy: 0.8183\n",
      "Epoch 389/400\n",
      "167/167 [==============================] - 57s 343ms/step - loss: 0.5345 - categorical_accuracy: 0.8264 - val_loss: 0.5520 - val_categorical_accuracy: 0.8140\n",
      "Epoch 390/400\n",
      "167/167 [==============================] - 57s 343ms/step - loss: 0.5254 - categorical_accuracy: 0.8300 - val_loss: 0.5109 - val_categorical_accuracy: 0.8143\n",
      "Epoch 391/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5289 - categorical_accuracy: 0.8279 - val_loss: 0.4793 - val_categorical_accuracy: 0.8209\n",
      "Epoch 392/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5229 - categorical_accuracy: 0.8306 - val_loss: 0.5753 - val_categorical_accuracy: 0.8169\n",
      "Epoch 393/400\n",
      "167/167 [==============================] - 57s 344ms/step - loss: 0.5213 - categorical_accuracy: 0.8298 - val_loss: 0.7417 - val_categorical_accuracy: 0.8191\n",
      "Epoch 394/400\n",
      "167/167 [==============================] - 58s 347ms/step - loss: 0.5301 - categorical_accuracy: 0.8276 - val_loss: 0.5743 - val_categorical_accuracy: 0.8175\n",
      "Epoch 395/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5314 - categorical_accuracy: 0.8292 - val_loss: 0.4476 - val_categorical_accuracy: 0.8152\n",
      "Epoch 396/400\n",
      "167/167 [==============================] - 57s 344ms/step - loss: 0.5310 - categorical_accuracy: 0.8289 - val_loss: 0.7530 - val_categorical_accuracy: 0.8161\n",
      "Epoch 397/400\n",
      "167/167 [==============================] - 58s 345ms/step - loss: 0.5446 - categorical_accuracy: 0.8259 - val_loss: 0.6519 - val_categorical_accuracy: 0.8161\n",
      "Epoch 398/400\n",
      "167/167 [==============================] - 57s 343ms/step - loss: 0.5280 - categorical_accuracy: 0.8291 - val_loss: 0.4865 - val_categorical_accuracy: 0.8188\n",
      "Epoch 399/400\n",
      "167/167 [==============================] - 58s 346ms/step - loss: 0.5354 - categorical_accuracy: 0.8276 - val_loss: 0.6417 - val_categorical_accuracy: 0.7989\n",
      "Epoch 400/400\n",
      "167/167 [==============================] - 57s 341ms/step - loss: 0.5506 - categorical_accuracy: 0.8241 - val_loss: 0.5342 - val_categorical_accuracy: 0.8209\n"
     ]
    }
   ],
   "source": [
    "history1 = model.fit_generator(training_data, \n",
    "                              epochs=400, verbose=1,\n",
    "                              validation_data=validation_data\n",
    "                              )\n",
    "\n",
    "# history = model.fit(X[0:40000], y[0:40000],\n",
    "#                 epochs=10,\n",
    "#                 batch_size=256,\n",
    "#                 shuffle=True,\n",
    "#                 validation_data=(X[40001:], y[40001:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " 42/194 [=====>........................] - ETA: 1:09 - loss: 0.4672 - categorical_accuracy: 0.8437"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[256,32,124,124] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node dropout_1/cond/then/_0/dropout/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_float_Cast}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_keras_scratch_graph_1890]\n\nFunction call stack:\nkeras_scratch_graph\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-12d6d1af42c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m history3 = model3.fit_generator(training_data, \n\u001b[0;32m      2\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m                               \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m                               )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m                                             reset_metrics=False)\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[256,32,124,124] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node dropout_1/cond/then/_0/dropout/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_float_Cast}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_keras_scratch_graph_1890]\n\nFunction call stack:\nkeras_scratch_graph\n"
     ]
    }
   ],
   "source": [
    "historyfinal = modelfinal.fit_generator(training_data, \n",
    "                              epochs=1, verbose=1,\n",
    "                              validation_data=validation_data\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test pickled model\n",
    "X_test = pd.read_pickle('test_max_x')\n",
    "X_test=X_test.astype('float32')/255\n",
    "X_test = np.repeat(X_test.reshape(X_test.shape[0], 128, 128, 1), 1, axis=1)\n",
    "X_test[X_test<1-(50/255)] = 0\n",
    "with open('./model3.pickle', 'rb') as f:\n",
    "    model3=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.07418496e-09 1.93081451e-06 4.95986082e-02 ... 2.88441665e-02\n",
      "  1.20780155e-01 6.72577679e-01]\n",
      " [1.58177999e-30 2.40914687e-32 6.96566726e-19 ... 3.18993791e-03\n",
      "  6.21711151e-05 9.32174742e-01]\n",
      " [5.94942575e-17 1.39167646e-17 9.83370052e-11 ... 1.86273735e-02\n",
      "  4.79455106e-03 4.02500900e-03]\n",
      " ...\n",
      " [1.28068511e-31 3.02431614e-26 4.50333651e-12 ... 9.94234741e-01\n",
      "  2.75951065e-03 2.99282186e-03]\n",
      " [9.05084896e-19 1.51557014e-18 8.50667600e-14 ... 4.12329994e-02\n",
      "  1.74324811e-02 3.92892361e-02]\n",
      " [2.48011488e-31 7.79559386e-28 2.79060060e-13 ... 3.20667937e-07\n",
      "  9.37093079e-01 6.29065558e-02]]\n"
     ]
    }
   ],
   "source": [
    "predict=model3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f5d55dec50f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "predictions=np.zeros((10000,2),dtype=float)\n",
    "\n",
    "for i in range(predictions.shape[0]):\n",
    "    predictions[i][0]=i\n",
    "    predictions[i][1]=(predict[i]).argmax()\n",
    "pd.DataFrame(predictions).to_csv(\"./predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2auoYORJgFO6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "InceptionV3_full_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
